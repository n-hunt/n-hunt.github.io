---
layout: post
title: "Emergence is All You Need: Reconciling Modularity and the Positive Manifold"
date: 2026-01-20
---

> **Abstract**
>
> Charles Spearman’s identification of the "positive manifold"—the statistical phenomenon where performance on unrelated cognitive tasks correlates positively—established a psychometric hegemony that biological reality has failed to substantiate. We possess a metric ($g$) that predicts performance with reliability, yet the search for its physical substrate proves unfruitful: ubiquitous in the data; absent in the hardware. This short essay encloses the search space strictly within this ontological gap, and centralises on whether general intelligence serves as a "part" of the computational architecture, or if it is better described as a statistical fiction arising from system dynamics. I argue that the attempt to locate $g$ as a static entity constitutes a category error. Dismantling Spearman’s conception of "mental energy" through the lens of evolutionary modularity (Cosmides & Tooby, 2002) and a critique of "reification" (Gould, 1981) reveals that the "General Problem Solver" is implausible. Instead, by leveraging van der Maas’s mutualism model and Chollet’s algorithmic definitions, I propose that **$g$ must be reconceptualised as an emergent consequence.** I represent general intelligence as the efficiency of skill acquisition born from positive feedback loops between otherwise modular systems, distinct from any specific algorithm.

***

The existence of $g$ is a statistical imposition. In his seminal analysis of school children’s performance, Spearman (1904) confronted a data pattern that defied intuitions of disparate faculties: the "positive manifold." Performance correlates consistently across diverse cognitive abilities. For instance, a subject’s proficiency in distinguishing pitch robustly predicts their ability to translate Latin. This "indifference of the indicator" (Spearman, 1927) suggests that distinct neural machinery draws upon a shared, finite resource.

Spearman formalised this dependency through his two-factor theory, partitioning performance into task-specific abilities ($s$) and a general factor ($g$). He defined $g$ as a quantity of "mental energy" available to the entire cortex, giving biological weight to the statistical finding (Spearman, 1904). The epistemic weight of this position remains formidable because the metric works. As a predictive variable, $g$ accounts for approximately half the variance in diverse cognitive batteries (Carroll, 1993; Jensen, 1998), forecasting occupational status (Schmidt & Hunter, 1998) and life outcomes (Deary, 2012). We cannot deny the reality of $g$ without ignoring the most replicated anomaly in psychometrics, namely that if the mind were truly a collection of independent, domain-specific modules, the correlation matrix should be flat. It is not. The persistence of the positive manifold proves that something unifies cognition, regardless of whether Spearman’s inference about biological "energy" holds.

Metric utility offers no guarantee of a referent’s reality. Stephen Jay Gould (1981) dismantles Spearman’s claim as an instance of "reification"—the illicit conversion of an abstract concept into a concrete entity. The fact that a mathematical operation (factor analysis) can extract a primary component from a correlation matrix proves only that the variables are related, not that a single physical cause unites them. Gould compares this to the "General Inflationary Trend": we track the average price of goods without hallucinating a factory that manufactures "inflation." $g$ is a coordinate on a graph rather than an organ in the brain; a description of the data rather than an explanation of the architecture.

This scepticism is fortified by the computational demands of natural selection. Cosmides and Tooby (2002) argue that a "General Problem Solver" is an evolutionary impossibility. Biological systems evolve to solve specific adaptive problems (e.g., toxin avoidance or spatial navigation). A system designed to solve "everything" would be paralysed by the frame problem; without domain-specific priors to prune the search space, inference becomes computationally intractable. The mind is therefore better conceptualised as a "Swiss Army knife" of discrete modules; the single, undifferentiated blade does not exist. This creates a crisis for the definition of intelligence: if our hardware is modular (Cosmides & Tooby) and the "general factor" is a statistical artefact (Gould), the predictive power of the positive manifold becomes incomprehensible. The correlation persists, but its architect has been dissolved.

This paradox demands an ontological inversion: we must cease viewing $g$ as the architect of the system and recognise it as the architecture itself in motion—a consequence, not a cause. Van der Maas et al. (2006) circumvent the reification trap with the "mutualism model," demonstrating that the positive manifold can exist without a central power source. By modelling cognitive development as a dynamic system of coupled equations, they show that distinct modules—the kind mandated by Cosmides and Tooby—will naturally become correlated through interaction during development.

Positive feedback replaces central command. Consider the compounding arithmetic of development: an initial advantage in working memory does not merely allow a child to retain more digits; it accelerates the extraction of syntax patterns from ambient speech. This linguistic edge unlocks complex reasoning earlier, which in turn demands—and trains—greater attentional control. The variance at the starting line may be trivial, but the interaction is exponential. The positive manifold tracks the synchronisation of the system, requiring no 'central power source' to explain the correlation. Under this "mutualism," the correlation between maths and verbal skills is inevitable not because they run on the same hardware, but because they bootstrap each other. A bottleneck in one creates a drag coefficient on the others.

General intelligence is therefore an emergent property that stabilises over time. The positive manifold mirrors the structure of a highly integrated network, and this redefinition satisfies the "No Free Lunch" theorem. The brain remains a collection of specialised tools but because these tools engage in recursive growth, they produce the statistical appearance of unity. We see the correlated output and infer a unified source, missing the modular scramble that built it. $g$ is real, but it indexes system synergy; it is not a distinct biological organ.

This dynamic ontology requires a formal definition that decouples intelligence from mere competency. [François Chollet (2019)](https://arxiv.org/abs/1911.01547) distinguishes between priors (hard-coded knowledge or training data) and generalisation. A chess engine possesses skill; it maps states to actions, yet it lacks general intelligence, incapable of leveraging its dominance in chess to grasp checkers. It is strictly confined to the domain of its optimisation and unable to transfer its statistical dominance to a novel environment.

True general intelligence, therefore, is the efficiency of skill acquisition rather than the possession of skill. It is a measure of the conversion ratio, demonstrated by the efficacy of a system's abilities to convert a limited amount of new information (experience) into a new program (skill) that covers a valid search space. This definition aligns the psychometric reality with the computational architecture. If $g$ is the index of system synergy (van der Maas), then high $g$ manifests as the rapid self-organisation of existing modules to solve novel problems. Intelligence becomes the algorithmic efficiency of a system updating its own 'software' in response to entropy; a process distinct from static crystallised knowledge ($s$).

General intelligence is thus exposed as the statistical signature of a dynamic system. By rejecting Spearman’s "mental energy" in favour of van der Maas’s mutualism, we reconcile the modularity of the hardware with the unity of the output. $g$ is the efficiency of skill acquisition—the rate at which a system updates its priors. However, the scope of this "generality" warrants further scrutiny; the frequent dissociation between high cognitive $g$ and poor sensorimotor acquisition (like the average 'uncoordinated intellectual') implies that the positive manifold is constrained by the specific topology of the network (non-universal). Ultimately, to possess general intelligence is not omniscience. It is the computational plasticity required to adapt efficiently to the unknown.

### Bibliography

*   Carroll, John B. (1993). *Human Cognitive Abilities: A Survey of Factor-Analytic Studies*. Cambridge University Press.
*   Chollet, François. (2019). "On the Measure of Intelligence." *arXiv preprint arXiv:1911.01547*.
*   Cosmides, Leda, & Tooby, John. (2002). "Unraveling the Enigma of Human Intelligence." *American Psychological Association*.
*   Deary, Ian J. (2012). "Intelligence." *Annual Review of Psychology*.
*   Gould, Stephen Jay. (1981). *The Mismeasure of Man*. W. W. Norton & Company.
*   Jensen, Arthur R. (1998). *The g Factor: The Science of Mental Ability*. Praeger.
*   Schmidt, Frank L., & Hunter, John E. (1998). "The Validity and Utility of Selection Methods in Personnel Psychology." *Psychological Bulletin*.
*   Spearman, Charles. (1904). "General Intelligence," Objectively Determined and Measured. *The American Journal of Psychology*.
*   Spearman, Charles. (1927). *The Abilities of Man: Their Nature and Measurement*. Macmillan.
*   Van Der Maas, Han L., et al. (2006). "A Dynamical Model of General Intelligence: The Positive Manifold of Intelligence by Mutualism." *Psychological Review*.